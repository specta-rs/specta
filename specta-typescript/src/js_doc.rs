use std::{
    borrow::Cow,
    collections::{HashMap, HashSet},
    fmt::Write as _,
    path::{Path, PathBuf},
};

use specta::{
    SpectaID, TypeCollection,
    datatype::{DataType, Fields, Literal, NamedDataType, Primitive},
};
use std::borrow::Borrow;

use crate::{BigIntExportBehavior, Error, Format, Typescript};

/// JSDoc language exporter.
#[derive(Debug, Clone)]
#[non_exhaustive]
pub struct JSDoc {
    pub header: Cow<'static, str>,
    pub framework_header: Cow<'static, str>,
    pub bigint: BigIntExportBehavior,
    pub format: Format,
    pub serde: bool,
}

impl Default for JSDoc {
    fn default() -> Self {
        Self {
            header: Cow::Borrowed(""),
            framework_header: Cow::Borrowed(
                "// This file has been generated by Specta. DO NOT EDIT.",
            ),
            bigint: Default::default(),
            format: Default::default(),
            serde: false,
        }
    }
}

impl From<Typescript> for JSDoc {
    fn from(ts: Typescript) -> Self {
        Self {
            header: ts.header,
            framework_header: ts.framework_header,
            bigint: ts.bigint,
            format: ts.format,
            serde: ts.serde,
        }
    }
}

impl JSDoc {
    /// Construct a new JSDoc exporter with the default options configured.
    pub fn new() -> Self {
        Default::default()
    }

    /// Override the header for the exported file.
    /// You should prefer `Self::header` instead unless your a framework.
    #[doc(hidden)] // Although this is hidden it's still public API.
    pub fn framework_header(mut self, header: impl Into<Cow<'static, str>>) -> Self {
        self.framework_header = header.into();
        self
    }

    /// Configure a header for the file.
    ///
    /// This is perfect for configuring lint ignore rules or other file-level comments.
    pub fn header(mut self, header: impl Into<Cow<'static, str>>) -> Self {
        self.header = header.into();
        self
    }

    /// Configure the BigInt handling behaviour
    pub fn bigint(mut self, bigint: BigIntExportBehavior) -> Self {
        self.bigint = bigint;
        self
    }

    /// Configure the format
    pub fn format(mut self, format: Format) -> Self {
        self.format = format;
        self
    }

    /// TODO: Explain
    pub fn with_serde(mut self) -> Self {
        self.serde = true;
        self
    }

    /// Export the files into a single string.
    ///
    /// Note: This will return [`Error:UnableToExport`] if the format is `Format::Files`.
    pub fn export(&self, types: &TypeCollection) -> Result<String, Error> {
        export(self, types)
    }

    fn export_internal(
        &self,
        ndts: impl Iterator<Item = NamedDataType>,
        references: impl Iterator<Item = SpectaID>,
        types: &TypeCollection,
    ) -> Result<String, Error> {
        let mut out = self.header.to_string();
        if !out.is_empty() {
            out.push('\n');
        }
        out += &self.framework_header;
        out.push_str("\n");

        for sid in references {
            let ndt = types.get(sid).unwrap();
            out += "const { ";
            out += &ndt.name();
            out += " } = require(\"";
            // TODO: Handle `0` for module path elements
            for i in 1..ndt.module_path().split("::").count() {
                if i == 1 {
                    out += "./";
                } else {
                    out += "../";
                }
            }
            out += &ndt.module_path().replace("::", "/");
            out += "\");\n";
        }

        out.push_str("\n");

        for (i, ndt) in ndts.enumerate() {
            if i != 0 {
                out += "\n\n";
            }

            out += &export_jsdoc_type(self, &types, &ndt)?;
        }

        Ok(out)
    }

    /// Export the types to a specific file/folder.
    ///
    /// When configured when `format` is `Format::Files`, you must provide a directory path.
    /// Otherwise, you must provide the path of a single file.
    ///
    pub fn export_to(&self, path: impl AsRef<Path>, types: &TypeCollection) -> Result<(), Error> {
        let path = path.as_ref();

        if self.format == Format::Files {
            if self.serde {
                specta_serde::validate(types)?;
            }

            std::fs::create_dir_all(path)?;

            let mut files = HashMap::<PathBuf, Vec<NamedDataType>>::new();

            for ndt in types.into_sorted_iter() {
                let mut file_path = PathBuf::from(path);
                for m in ndt.module_path().split("::") {
                    file_path = file_path.join(m);
                }
                file_path.set_extension("js"); // JSDoc uses .js files
                files.entry(file_path).or_default().push(ndt);
            }

            let used_paths = files.keys().cloned().collect::<HashSet<_>>();

            for (path, ndts) in files {
                if let Some(parent) = path.parent() {
                    std::fs::create_dir_all(parent)?;
                }

                let mut references = HashSet::new();
                for ndt in ndts.iter() {
                    crawl_references(ndt.ty(), &mut references);
                }

                std::fs::write(
                    &path,
                    self.export_internal(ndts.into_iter(), references.into_iter(), types)?,
                )?;
            }

            if path.exists() && path.is_dir() {
                fn remove_unused_js_files(
                    dir: &Path,
                    used_paths: &HashSet<PathBuf>,
                ) -> std::io::Result<()> {
                    for entry in std::fs::read_dir(dir)? {
                        let entry = entry?;
                        let entry_path = entry.path();

                        if entry_path.is_dir() {
                            remove_unused_js_files(&entry_path, used_paths)?;

                            // Remove empty directories
                            if std::fs::read_dir(&entry_path)?.next().is_none() {
                                std::fs::remove_dir(&entry_path)?;
                            }
                        } else if entry_path.extension().and_then(|ext| ext.to_str()) == Some("js")
                        {
                            if !used_paths.contains(&entry_path) {
                                std::fs::remove_file(&entry_path)?;
                            }
                        }
                    }
                    Ok(())
                }

                let _ = remove_unused_js_files(path, &used_paths);
            }
        } else {
            if let Some(parent) = path.parent() {
                std::fs::create_dir_all(parent)?;
            }

            std::fs::write(
                &path,
                self.export(types).map(|s| format!("{}{s}", self.header))?,
            )?;
        }

        Ok(())
    }
}

pub(crate) fn export(jsdoc: &JSDoc, types: &TypeCollection) -> Result<String, Error> {
    if jsdoc.serde {
        specta_serde::validate(types)?;
    }

    match jsdoc.format {
        Format::Namespaces => {
            let mut out = jsdoc.export_internal([].into_iter(), [].into_iter(), types)?;
            let mut module_types: HashMap<_, Vec<_>> = HashMap::new();

            for ndt in types.into_unsorted_iter() {
                module_types
                    .entry(ndt.module_path().to_string())
                    .or_default()
                    .push(ndt.clone());
            }

            fn export_module(
                types: &TypeCollection,
                jsdoc: &JSDoc,
                module_types: &mut HashMap<String, Vec<NamedDataType>>,
                current_module: &str,
                indent: usize,
            ) -> Result<String, Error> {
                let mut out = String::new();
                if let Some(types_in_module) = module_types.get_mut(current_module) {
                    types_in_module
                        .sort_by(|a, b| a.name().cmp(b.name()).then(a.sid().cmp(&b.sid())));
                    for ndt in types_in_module {
                        let prefix = "    ".repeat(indent);
                        out += &prefix;
                        out += &export_jsdoc_type(jsdoc, types, ndt)?;
                        out += "\n\n";
                    }
                }

                let mut child_modules = module_types
                    .keys()
                    .filter(|k| {
                        k.starts_with(&format!("{}::", current_module))
                            && k[current_module.len() + 2..].split("::").count() == 1
                    })
                    .cloned()
                    .collect::<Vec<_>>();
                child_modules.sort();

                for child in child_modules {
                    let module_name = child.split("::").last().unwrap();
                    let prefix = "    ".repeat(indent);
                    out += &prefix;
                    out += &format!("// Module: {module_name}\n");
                    out += &export_module(types, jsdoc, module_types, &child, indent + 1)?;
                }

                Ok(out)
            }

            let mut root_modules = module_types.keys().cloned().collect::<Vec<_>>();
            root_modules.sort();

            for (i, root_module) in root_modules.iter().enumerate() {
                if i != 0 {
                    out += "\n";
                }
                out += &format!("// Module: {}\n", root_module);
                out += &export_module(types, jsdoc, &mut module_types, root_module, 0)?;
            }

            Ok(out)
        }
        Format::Files => Err(Error::UnableToExport),
        Format::FlatFile | Format::ModulePrefixedName => {
            if jsdoc.format == Format::FlatFile {
                let mut map = HashMap::with_capacity(types.len());
                for dt in types.into_unsorted_iter() {
                    if let Some((existing_sid, existing_impl_location)) =
                        map.insert(dt.name().clone(), (dt.sid(), dt.location()))
                    {
                        if existing_sid != dt.sid() {
                            return Err(Error::DuplicateTypeName {
                                types: (dt.location(), existing_impl_location),
                                name: dt.name().clone(),
                            });
                        }
                    }
                }
            }

            jsdoc.export_internal(types.into_sorted_iter(), [].into_iter(), types)
        }
    }
}

fn export_jsdoc_type(
    jsdoc: &JSDoc,
    types: &TypeCollection,
    ndt: &NamedDataType,
) -> Result<String, Error> {
    let name = crate::legacy::sanitise_type_name(
        crate::legacy::ExportContext {
            cfg: &Typescript {
                header: jsdoc.header.clone(),
                framework_header: jsdoc.framework_header.clone(),
                bigint: jsdoc.bigint,
                format: jsdoc.format,
                serde: jsdoc.serde,
                jsdoc: true,
            },
            path: vec![],
            is_export: false,
        },
        crate::legacy::NamedLocation::Type,
        &match jsdoc.format {
            Format::ModulePrefixedName => {
                let mut s = ndt.module_path().split("::").collect::<Vec<_>>().join("_");
                s.push_str("_");
                s.push_str(ndt.name());
                Cow::Owned(s)
            }
            _ => ndt.name().clone(),
        },
    )?
    .leak(); // TODO: Leaking bad

    let mut result = crate::legacy::js_doc_builder(ndt.docs(), ndt.deprecated()).build();

    // Generate JSDoc typedef
    result.push_str(&format!("/**\n * @typedef {{"));

    // Generate the type definition
    let mut type_def = String::new();
    datatype_jsdoc(
        &mut type_def,
        jsdoc,
        types,
        ndt.ty(),
        vec![ndt.name().clone()],
        true,
        Some(ndt.sid()),
    )?;

    result.push_str(&type_def);
    result.push_str(&format!("}} {}\n */\n", name));

    Ok(result)
}

fn datatype_jsdoc(
    s: &mut String,
    jsdoc: &JSDoc,
    types: &TypeCollection,
    dt: &DataType,
    location: Vec<Cow<'static, str>>,
    is_export: bool,
    sid: Option<SpectaID>,
) -> Result<(), Error> {
    match dt {
        DataType::Primitive(p) => {
            let ts_type = primitive_dt(&jsdoc.bigint, p, location)?;
            // Convert TypeScript types to JSDoc types
            let jsdoc_type = match ts_type {
                "string" => "string",
                "number" => "number",
                "boolean" => "boolean",
                "bigint" => "bigint",
                _ => ts_type,
            };
            s.push_str(jsdoc_type);
        }
        DataType::Literal(l) => literal_dt(s, l),
        DataType::List(l) => {
            datatype_jsdoc(s, jsdoc, types, l.ty(), location, is_export, sid)?;
            s.push_str("[]");
        }
        DataType::Map(m) => {
            s.push_str("Object<");
            datatype_jsdoc(
                s,
                jsdoc,
                types,
                m.key_ty(),
                location.clone(),
                is_export,
                sid,
            )?;
            s.push_str(", ");
            datatype_jsdoc(s, jsdoc, types, m.value_ty(), location, is_export, sid)?;
            s.push_str(">");
        }
        DataType::Nullable(def) => {
            s.push_str("(");
            datatype_jsdoc(s, jsdoc, types, def, location, is_export, sid)?;
            s.push_str(" | null)");
        }
        DataType::Struct(st) => {
            // For JSDoc, we need to traverse the struct fields to check for BigInt errors
            crawl_references_fields(&st.fields(), &mut HashSet::new());
            // Check fields for BigInt types that should error
            check_struct_fields_for_bigint_errors(&st.fields(), &jsdoc.bigint, location.clone())?;
            // For JSDoc, we'll represent structs as Object
            s.push_str("Object");
        }
        DataType::Enum(e) => {
            // For JSDoc, we need to traverse enum variants to check for BigInt errors
            for (_, variant) in e.variants() {
                check_struct_fields_for_bigint_errors(
                    &variant.fields(),
                    &jsdoc.bigint,
                    location.clone(),
                )?;
            }
            // For JSDoc, we'll represent enums as string unions or Object
            s.push_str("Object");
        }
        DataType::Tuple(t) => {
            s.push_str("[");
            for (i, element) in t.elements().iter().enumerate() {
                if i > 0 {
                    s.push_str(", ");
                }
                datatype_jsdoc(s, jsdoc, types, element, location.clone(), is_export, sid)?;
            }
            s.push_str("]");
        }
        DataType::Reference(r) => {
            if let Some(ndt) = types.get(r.sid()) {
                s.push_str(&ndt.name());
            } else {
                s.push_str("Object");
            }
        }
        DataType::Generic(g) => s.push_str(g.borrow()),
    }

    Ok(())
}

fn primitive_dt(
    b: &BigIntExportBehavior,
    p: &Primitive,
    location: Vec<Cow<'static, str>>,
) -> Result<&'static str, Error> {
    use Primitive::*;

    Ok(match p {
        i8 | i16 | i32 | u8 | u16 | u32 | f32 | f16 | f64 => "number",
        usize | isize | i64 | u64 | i128 | u128 => match b {
            BigIntExportBehavior::String => "string",
            BigIntExportBehavior::Number => "number",
            BigIntExportBehavior::BigInt => "bigint",
            BigIntExportBehavior::Fail => {
                return Err(Error::BigIntForbidden {
                    path: location.join("."),
                });
            }
        },
        Primitive::bool => "boolean",
        String | char => "string",
    })
}

fn literal_dt(s: &mut String, l: &Literal) {
    use Literal::*;

    match l {
        i8(v) => write!(s, "{v}"),
        i16(v) => write!(s, "{v}"),
        i32(v) => write!(s, "{v}"),
        u8(v) => write!(s, "{v}"),
        u16(v) => write!(s, "{v}"),
        u32(v) => write!(s, "{v}"),
        f32(v) => write!(s, "{v}"),
        f64(v) => write!(s, "{v}"),
        bool(v) => write!(s, "{v}"),
        String(v) => write!(s, "\"{v}\""),
        char(v) => write!(s, "\"{v}\""),
        None => write!(s, "null"),
        // We panic because this is a bug in Specta.
        v => unreachable!("attempted to export unsupported LiteralType variant {v:?}"),
    }
    .expect("writing to a string is an infallible operation");
}

fn check_struct_fields_for_bigint_errors(
    fields: &Fields,
    bigint_behavior: &BigIntExportBehavior,
    location: Vec<Cow<'static, str>>,
) -> Result<(), Error> {
    match fields {
        Fields::Unit => Ok(()),
        Fields::Unnamed(fields) => {
            for (i, field) in fields.fields().iter().enumerate() {
                if let Some(ty) = field.ty() {
                    let mut field_location = location.clone();
                    field_location.push(i.to_string().into());
                    check_datatype_for_bigint_errors(ty, bigint_behavior, field_location)?;
                }
            }
            Ok(())
        }
        Fields::Named(fields) => {
            for (name, field) in fields.fields() {
                if let Some(ty) = field.ty() {
                    let mut field_location = location.clone();
                    field_location.push(name.clone());
                    check_datatype_for_bigint_errors(ty, bigint_behavior, field_location)?;
                }
            }
            Ok(())
        }
    }
}

fn check_datatype_for_bigint_errors(
    dt: &DataType,
    bigint_behavior: &BigIntExportBehavior,
    location: Vec<Cow<'static, str>>,
) -> Result<(), Error> {
    match dt {
        DataType::Primitive(p) => {
            primitive_dt(bigint_behavior, p, location)?;
            Ok(())
        }
        DataType::List(l) => check_datatype_for_bigint_errors(l.ty(), bigint_behavior, location),
        DataType::Map(m) => {
            check_datatype_for_bigint_errors(m.key_ty(), bigint_behavior, location.clone())?;
            check_datatype_for_bigint_errors(m.value_ty(), bigint_behavior, location)
        }
        DataType::Nullable(def) => check_datatype_for_bigint_errors(def, bigint_behavior, location),
        DataType::Struct(st) => {
            check_struct_fields_for_bigint_errors(&st.fields(), bigint_behavior, location)
        }
        DataType::Enum(e) => {
            for (_, variant) in e.variants() {
                check_struct_fields_for_bigint_errors(
                    &variant.fields(),
                    bigint_behavior,
                    location.clone(),
                )?;
            }
            Ok(())
        }
        DataType::Tuple(t) => {
            for (i, element) in t.elements().iter().enumerate() {
                let mut elem_location = location.clone();
                elem_location.push(i.to_string().into());
                check_datatype_for_bigint_errors(element, bigint_behavior, elem_location)?;
            }
            Ok(())
        }
        DataType::Reference(_) | DataType::Generic(_) | DataType::Literal(_) => Ok(()),
    }
}

fn crawl_references(dt: &DataType, references: &mut HashSet<SpectaID>) {
    match dt {
        DataType::Primitive(..) | DataType::Literal(..) => {}
        DataType::List(list) => {
            crawl_references(list.ty(), references);
        }
        DataType::Map(map) => {
            crawl_references(map.key_ty(), references);
            crawl_references(map.value_ty(), references);
        }
        DataType::Nullable(dt) => {
            crawl_references(dt, references);
        }
        DataType::Struct(s) => {
            crawl_references_fields(&s.fields(), references);
        }
        DataType::Enum(e) => {
            for (_, variant) in e.variants() {
                crawl_references_fields(&variant.fields(), references);
            }
        }
        DataType::Tuple(tuple) => {
            for field in tuple.elements().iter() {
                crawl_references(field, references);
            }
        }
        DataType::Reference(reference) => {
            references.insert(reference.sid());
        }
        DataType::Generic(_) => {}
    }
}

fn crawl_references_fields(fields: &Fields, references: &mut HashSet<SpectaID>) {
    match fields {
        Fields::Unit => {}
        Fields::Unnamed(fields) => {
            for field in fields.fields() {
                if let Some(ty) = field.ty() {
                    crawl_references(ty, references);
                }
            }
        }
        Fields::Named(fields) => {
            for (_, field) in fields.fields() {
                if let Some(ty) = field.ty() {
                    crawl_references(ty, references);
                }
            }
        }
    }
}
